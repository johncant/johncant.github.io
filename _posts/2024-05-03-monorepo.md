---
layout: default
title:  "A Small Python Monorepo"
---

# How I set up a small Python monorepo

I decided to put together a personal project for my own trading analytics. It would need to contain a few python packages, a few data pipelines, and maybe some dashboards and APIs.

[pants](https://www.pantsbuild.org/) looks like a good tool for working with monorepos, but we don't need it.

### Why a monorepo?

Consider 3 packages `A`, `B`, and `C`, where `A` depends on `B`, which depends on `C`. `A -> B -> C`

Suppose you want to make a small change to A that requires small changes to B and C.

In the multiple repo world, you can do this

  - `git clone A`
  - `git clone B`
  - `git clone C`
  - Alter A to depend on your local B and C
  - Make changes to A B and C
  - commit changes to C, submit pull request, get it merged, get it released
  - commit changes to B, submit pull request, get it merged, get it released
  - commit changes to A, submit pull request, get it merged, get it released

This takes time, particularly if you're doing peer review for your pull requests (I use PRs and review them myself even if no-one else will see my code) or waiting for a slow CI. They depend on eachother. no-one should merge your B-changes until your C-changes are merged, since this will break B, and no-one should merge your A-changes into A until your B changes are merged.

The main issue is the latency of getting something merged. In this scenario, it takes 3 slow interpersonal transactions (waiting for a colleague to merge your PRs, which is entirely dependent on how busy they are. In particular, when working with data scientists or juniors, a large proportion of them might not like reviewing pull requests and might not prioritize it.

However, in the monorepo world, you can do this:

  - `git clone monorepo`
  - Make changes to A B and C
  - Commit, then get all changes merged simultaneously via one PR, including a version bump to all 3 packages.

It's now one simpler interpersonal transaction, reducing the latency and allowing your changes to be shipped quicker.

Furthermore, you are now forced to separate your concerns into different packages, resulting in your project being easier for other people to understand.

### Packaging

Recommend `poetry`.

### File structure

In this example we're going to have a python package called `lake`, which is a package for interacting with a data lake. We'll also have a package called warehouse, responsible for building and querying a data warehouse based on the data lake.

We'll also have some data pipelines, pipeline1 and pipeline2, which will both be deployed as docker images.

    johnrepo/
    ├─ lake/
    │  ├─ README.md
    │  ├─ pyproject.toml
    │  ├─ johnrepo/
    │  │  ├─ lake/
    │  │     ├─ some_module.py
    │  ├─ tests/
    ├─ warehouse/
    │  ├─ README.md
    │  ├─ pyproject.toml
    │  ├─ johnrepo/
    │  │  ├─ warehouse/
    │  │     ├─ some_module.py
    │  ├─ tests/
    ├─ pipelines/
    │  ├─ pipeline1/
    │     ├─ README.md
    │     ├─ pyproject.toml
    │     ├─ Dockerfile
    │     ├─ johnrepo/
    │     │  ├─ pipelines/
    │     │     ├─ pipeline1/
    │     │        ├─ pipeline_code.py
    │     ├─ tests/
    ├─ pipelines/
    │  ├─ pipeline2/
    │     ├─ README.md
    │     ├─ pyproject.toml
    │     ├─ Dockerfile
    │     ├─ johnrepo/
    │     │  ├─ pipelines/
    │     │     ├─ pipeline2/
    │     │        ├─ pipeline_code.py
    │     ├─ tests/
    ├─ pyproject.toml
    ├─ README.md
    ├─ johnrepo_dev/

It's very simple - there are two packages, `lake` and `warehouse`, and two pipelines which use the packages.

At the top level, we have a root pyproject.toml, which will help us install all our dependencies.

Any code at top level cannot be reused, so you only want to put things like scripts and any utils they use here, if at all. It will almost always be better to put code in a subpackage.

### Split packages

These packages all provide the package `johnrepo`.

Normally, you have an `__init__.py` at each level of your package, like so:

    ├─ README.md
    ├─ pyproject.toml
    ├─ foo/
    │  ├─ __init__.py
    │  ├─ bar/
    │  │  ├─ __init__.py
    │  │  ├─ baz.py

But in our case, several parts of the monorepo define the package johnrepo, leading to conflicts. The solution is really simple, and it's not to include `__init__.py` in all the shared subpackages as per [this guide](https://packaging.python.org/en/latest/guides/packaging-namespace-packages/#native-namespace-packages), which explains how to split a package into multiple "distribution packages" in python 3.3+.

We also need to tell poetry where to find our package files, since its name will be different to the "distribution package" name we define (`johnrepo-lake` here, in `lake/pyproject.toml`)

    [tool.poetry]
    name = "johnrepo-lake"
    version = "0.1.0"
    description = ""
    authors = ["..."]
    readme = "README.md"
    packages = [{include = "johnrepo"}]

### Poetry hierarchy

For development, you will want to quickly install all the dependencies from one place, and make them editable, using one command. So, your top-level `pyproject.toml` needs to look something like this:

    [tool.poetry]
    name = "johnrepo_dev"
    version = "0.1.0" # Never needs to be incremented

    [tool.poetry.dependencies]
    johnrepo-lake = { path = "./lake", develop = true }
    johnrepo-warehouse = { path = "./warehouse", develop = true }
    johnrepo-pipelines_pipeline1 = { path = "./pipelines/pipeline1", develop = true }
    johnrepo-pipelines_pipeline2 = { path = "./pipelines/pipeline2", develop = true }

After running `poetry lock` at the top level, you should commit `poetry.lock`, since `poetry lock` has found a set of mutually compatible dependencies amongst all your subpackages. This can take time when done from scratch, so its best to keep the result. The reliability benefits of keeping your poetry lockfile are not realised in this case.

When you install the top level package, your local subpackages are installed in editable mode, and your changes are immediately reflected.

For a pipeline, your `pyproject.toml` needs to look like this:

    [tool.poetry]
    name = "johnrepo_pipelines_pipeline2"
    version = "0.3.0"

    [tool.poetry.dependencies]
    johnrepo-lake = ">0.5.0"
    johnrepo-warehouse = ">0.6.0"

The versions of packages from this repo used here are constrained, possibly because of new functionality you added which you need.

If you installed the top-level package using poetry install, AND it succeeds, then your editable local packages in the monorepo will already satisfy the version constraints specified here, so this will work for local development without having to make any extra changes.

### Development dependencies

If you specify development dependencies in a subpackage, then run `poetry install` at the top level, the development dependencies will not be installed.

To get round this, I added a new subpackage called `testing` which depended on all the dev dependencies needed for testing. Every package would have `testing` as a dev dependency, but the top-level package would depend on `testing` as a regular dependency.

All the type annotation packages just went into the top level `pyproject.toml`.

All my development dependencies were either for testing, or were type annotations, so this completely solved the problem.

### CI/CD

Don't repeat yourself, and you can save on copy/pasting unnecessary boilerplate.

Here's what my github (actually gitea) actions workflow looks like:

.github/workflows/tests.yml

    name: Run tests

    jobs:
      tests:
        strategy:
          matrix:
            package_dir:
              - lake
              - warehouse
              - pipelines/pipeline1
              - pipelines/pipeline2
        env:
          RUNNER_TOOL_CACHE: /toolcache
        runs-on: ubuntu-latest
        container: catthehacker/ubuntu:act-latest
        steps:
            ...

You can reuse the same steps for every package in your repo. You can also do this for deployment, which saves a huge amount of time!

### Issues

In this setup, your pipelines and web apps will be deployed with any set of dependencies that matches the constraints in their pyproject.toml. It's implicitly assumed (incorrectly) that any dependencies matching those constraints will work.

For packages, this is OK, and if a dependency version causes problems, you should fix the package, or adjust the constraints.

However, for applications (including pipelines), you should lock all dependencies to specific versions, i.e. run `poetry lock` and commit `poetry.lock`. This guarantees they will be deployed with the same dependencies they were developed with. Unfortunately, if we do this naively, then `poetry.lock` will contain relative paths to our subpackages, which is unhelpful when it comes to deployment.

Sorry, I don't have an easy solution, and for personal use I am prepared to tolerate not locking my dependencies.

### But what about performance issues involving large files or large numbers of commits?

I am not the size of Google and most likely neither are you. Once your repo becomes big enough, you probably have enough skills or enough skilled colleagues to solve any problems that arise. Until then, we can benefit from having a simple monorepo setup

### Conclusion

Seting up a monorepo for a python project is really easy and I recommend doing it, if you stand to benefit from code reuse.
